{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f3e011c90a5eff2d4d66329ea0a5a764febab58b840653b9504a7828f9d941a1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_data import get_all_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dicts(dict1,dict2):\n",
    "    #Adds two dicts by adding the values\n",
    "    res = {}\n",
    "    res.update(dict2)\n",
    "    for key,value in dict1.items():\n",
    "        if key in res: res[key] += value\n",
    "        else: res[key] = value\n",
    "    \n",
    "    return res\n",
    "\n",
    "def add_to_dict(dict,key,value = 1):\n",
    "    #Add a value to a dict at \"key\"\n",
    "    if key in dict: dict[key] +=value\n",
    "    else: dict[key] = value\n",
    "\n",
    "def unpack_nested_dict(d,sep = \"_\"):\n",
    "    #Unpacks the dicts within a dict. Concats the keys with a seperator and returns a \"flat\" dict\n",
    "    res = {}\n",
    "    for key,value in d.items():\n",
    "        if isinstance(value,dict):\n",
    "            for k,v in value.items():\n",
    "                res[key+sep+k] = v\n",
    "        else:\n",
    "            res[key] = value\n",
    "\n",
    "    return res\n",
    "\n",
    "def propergate_embeddings(soup,depth = 0,parents = {},y_pos = 0):\n",
    "    #Goes trough the soup tree and sets the embeddings for each soup\n",
    "    all_children_counts = {}\n",
    "    direct_children_counts = {}\n",
    "\n",
    "    embeddings = {}\n",
    "\n",
    "    #y_pos describes the y-position of an element on the page\n",
    "    embeddings[\"y_pos\"] = y_pos\n",
    "\n",
    "    if soup.children:\n",
    "        for child in soup.children:\n",
    "            if child.name:\n",
    "                add_to_dict(direct_children_counts,child.name)\n",
    "                add_to_dict(all_children_counts,child.name)\n",
    "                all_children_counts = add_dicts(all_children_counts,propergate_embeddings(child,depth+1,parents = add_dicts(parents,{soup.name:1}),y_pos=y_pos))\n",
    "                y_pos += 1\n",
    "                pass\n",
    "\n",
    "    \n",
    "    #The number of words that are directly in the element\n",
    "    embeddings[\"direct_word_count\"] = len((soup.find(text=True,recursive = False) or \"\").split())\n",
    "\n",
    "    #The number of words from all elements\n",
    "    embeddings[\"all_word_count\"] = len(soup.text.split())\n",
    "    \n",
    "    #A dict with the numbers of elements by \"name\"\n",
    "    embeddings[\"child_counts\"] = all_children_counts\n",
    "\n",
    "    #A dict with the numbers of elements by \"name\" of direct children\n",
    "    embeddings[\"direct_child_counts\"] = direct_children_counts\n",
    "\n",
    "    #A dict with the key and value of the current element\n",
    "    embeddings[\"class\"] = {soup.name:1}\n",
    "\n",
    "    #The depth of an element\n",
    "    embeddings[\"depth\"] = depth\n",
    "\n",
    "    #A dict of parents \"name\" with counts of the element \n",
    "    embeddings[\"parents\"] = parents\n",
    "    \n",
    "\n",
    "\n",
    "    soup.embeddings = unpack_nested_dict(embeddings)\n",
    "\n",
    "    #For recursive execution, the child_counts are returned\n",
    "    return all_children_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the soups with labels\n",
    "soups = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_and_classified  =[]\n",
    "\n",
    "for soup in soups:\n",
    "    propergate_embeddings(soup)\n",
    "\n",
    "    labeled_and_classified += soup.find_all()\n",
    "\n",
    "df = pd.DataFrame([s.embeddings for s in labeled_and_classified])\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "df[\"label\"] = [s.label for s in labeled_and_classified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is split up into positive and negative to then be balanced\n",
    "neg = df[df.label != \"article\"]\n",
    "pos = df[df.label == \"article\"]\n",
    "\n",
    "n = min(len(pos),len(neg))\n",
    "\n",
    "data = pd.concat([pos.sample(n=n),neg.sample(n=n)])\n",
    "\n",
    "data[\"label\"] = data.label.map(lambda x: \"article\" if x == \"article\" else \"not_article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}